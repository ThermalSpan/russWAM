\documentclass{article}
\usepackage{fullpage}

\begin{document}
\title{Report}
\author{Russell Bentley}
\maketitle

\section{Introduction}
This indepentdent study has been a long project. Through it I have explored interesting subject material, gained valuable insight into larger software projects, and earned expereince programming and using several different tools. In the end I built a tool capable of evaluating a subset of prolog. At the same time, I could have used my time during the semester more productivly, which could have a resulted in a more complete final product. To expand on what went well, and what went bad, I would like to break this report down. 

\section{Tools}
This project was an undeniable success when it came to learning about the tools available to me. To start with, I really got the hang of using Makefiles. The time I put in to learning about Make for this project allowed me to quickly start using Makefiles in a number of other situations. I am now capable of setting a up a build system for a larger project, something I could not have said before. Learning more about Make was key success early on that gave me the infrastructure to learn other tools.

The next set of tools I'd like to mention is Bison and Flex, and semantic analysis. It should be noted that these were skills I learned in my Compilers course over the semester. However, this project provided a place to apply those ideas in a different setting. In order to use the WAM code generated by \verb{pl2wam} I had to use all three of these tools in order to translate that code into a data structure that my WAM implementation could use (FunctorTable.) The expereience was further improved after failings in my first attempt prompted a complete rewrite of the system. In the end I was able to build a robust WAM code parser that could detect a great deal of errors before even starting the WAM. Bison and Flex will be useful in future projects, and I am very pleased to have them in my skillset.

Another importnat set of tools is valgrind and gdb. I had no real exposure to either of these tools before this semester, yet I was commited to developing this commandline tools. First, a having a debugger proved to be essential. While I barely scratched the surface of what gdb has to offer, I was able to use it to quickly find errors in both program correctness, and program behaivor. Similiarly, valgrind was an amazing tool helping me use memory safely. This proved particularly useful when building the syntax tree for WAM code. These are two tools I will be using quite frequently here on out, expecially in conjunction with the next tool I want to mention.

The most important tool I learned about this semester was c++. I say this semester becuase I was also using c++ at work and in my Compilers course. However, having this project gave me a reason to write far more c++ that I would have otherwise. In addition, it was a style of code that I have never written before: very close to the metal so to speak. I gained intuition on how to use pointers. I became more competent with \verb{malloc} and \verb{free}. I debugged strange new behaivors I'd never seen. My favorite such instance was when I had a descrutor calling delete on a pointer that was neither equal to the null pointer no allocated memory. The destructorw as called for a stack allocated object, so the program seemed to segfault upon returning from a certain function call, and resulted in a stack trace that was absolute gibberish. I find that I can now write far more c++ without consulting the documentation that I could have before. The result of all this is that c++ is now my go to language if I want to build something. In conjunction with the other tools I learned about while working on this project, I feel far more capable to producing working software "from the ground up." So to speak.

\section{The WAM}
Implementing the WAM of course required me to become familiar with its inner workings. To that end, Hassan's tutorial reconstruction was an invaluable resource, however I also found , and  to be helpful at times. Of course, my largest misuse of time was dilly dallying in the tutorial and not looking at the big picture earlier in the semester. Hassan's evolutionary approach to explaining the WAM is fantastic, however it requires non-trivial and structural changes to the code base if someone wanted a working copy of each stage of his explanation. Which is what I was trying to do for around three quarters of the semester. The brightside was that I was forced to rewrite of my project, essentially from scratch. I think this allowed me to have nicer code in the end. 

In its original form, the WAM was a memory architecture combined with an instruction set. What that means is that the the original paper described how to break up an entire address space for use with the WAM.

\subsection {Data Areas}
At its core, the WAM manipulates DataCells. A DataCell has a tag and some other peice of information, usually a reference to another DataCell or a reference to some functor. The WAM has several data areas that is uses to store information. The original description has these data areas as parts of a memory achitecture, which is to say they were meant to divide up one contiguous address space. My implementation is not that strict and does not require all the data to be in one address space. As such, I could not use the tests based on a DataCell's relative locations, which were quite common in the WAM's original description. I will now describe these data areas, both as they were originally intended, and as I implemented them. 
\subsubsection{The Heap}\\
The heap is essentially a large array of DataCells. Representations of prolog predicates are built on the heap, which are in turn used in the unification process. I stayed very simple with this one. The heap is simply an array of DataCells. I would need to spend more time looking at other prolog systems to decide how the heap would be best handled, as I there were a number of things I didn't worry about. These include, garbage collection, having a dynammically sized heap, and bounds checking.

\subsubsection{The Trail}\\
The trail was meant to be an array of DataCell addresses. Sometimes during unificaton, unbound reference cells get bound to other values in a way that would need to be undone when backtracking. The trail is where the addresses of cells to be unbound upon backtracking are stored. I stayed simple with this one too, in the same manner as the heap.

\subsubsection{THe PDL}
The push down list (PDL) is a stack used during general unification to keep track of the next pair of addresses to be unified. I opted to use the standard library's stack.

\subsubsection{The Stack}
The stack was mean to hold both environment frames and choice points. Environment frames hole local registers used during the evaluation of a given rule. Choice points hold the state of the WAM as a sort of ``checkpoint'' to backtrack too. It was mentioned in \cite{} that seperating the stack into two seperate stacks was a common modification to the WAM. I implemented it as two seperate linked lists, where each node was frame or point respectivley. The WAM knows the head of each list which allows it use the structures as stacks. 

\subsubsection{The Code}
The code area is simply where the WAM code lives in memory. This is my biggest departure from the original description, though both the original and the tutorial did not speak to practical implementation. The code in my implementation is stored in a larger data structure called the functor table. The full purpose of the functor table will be described shortly. That being said, I chose to store instructions as ``words'' much like mips, where each one has an operation code and up to three integer arguments. Here they are called WAMwords

\subsection{WAM State}
In addition to the data areas, the WAM uses a set of registers to maintian its state. These registers vary in their use and content. 

\subsubsection{H, HB, and S}
These are DataCell address registers. The H register points into the heap to the next write location. Whenever a represention is to built on the heap, it goes where H is pointing. HB is the backtracking point on the heap. That is, HB will always be equal to or behind H, ssuch that setting H to HB would effectivly erase all new representations since the last choice point. S is used during unification to point to the next DataCell to be unified. 

\subsubsection{P and CP}
These are WAMword address registers. The P register is the next instruction to be run. Most instructons increment this register, or otherwise modify it, upon completion. The CP register is the continuation point. Whenever a predicate is done running (perhaps only for the moment) it will use the CP register to return to the callee predicate.

\subsubsection{B and B0}
These are choice point registers. B points to the latest choice point, which in turn has a reference to the previous choice point, and so on. B0 is also known as the cut pointer, and is the last choice point before a cut. 

\subsubsection{E}
This is a Environment frame registers. It points to the current environment frame, which in turn points to the previous one, and so one. 

\subsubsection{TR}
This is register stores the address of a  DataCell address in the Trail. In conjuction with an older TR from a choice point it used to reset swathes of the trail during backtracking. 

\subsubsection{Global Argument Registers}
These are data cell registers, and there can be many of them. They are used to store and return the results of a query. You need as many as there are unknowns in any predicate called during a query. 

\subsection{Functor Table}
This data strucutre is how my implementaiton of the WAM access all the information pertaining to functors (predicates and atoms). First, it uses a hash map to assign a unique integer id to each functor name, functor arity pair. The functor table also maintiains a set of information for each functor including an array of WAMwords, a string name, and another map that takes functors to code labels. See Figure ~\ref{}.

\section{Conclusion}
dssdsfdg

\end{document}

